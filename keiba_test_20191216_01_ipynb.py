# -*- coding: utf-8 -*-
"""keiba_test_20191216_01.ipynb のコピー

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zuypcu675WyPvg6EhBSpgIiYjLEdMPgK
"""

# Commented out IPython magic to ensure Python compatibility.
#import 
import pandas as pd
import numpy as np
import re
import sklearn
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore')

# Going to use these 5 base models for the stacking
from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, 
                              GradientBoostingClassifier, ExtraTreesClassifier)
from sklearn.svm import SVC
from sklearn.model_selection import KFold

from collections import defaultdict

import numpy as np
#from tqdm import tqdm
from sklearn import datasets
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.naive_bayes import GaussianNB

# show upload dialog

data = pd.read_csv('seikika3.csv')

t=np.array(data['入賞']).T

t_pd=pd.DataFrame(t)

x = np.array([data["人気"],data["馬番"],data["斤量"],data["単勝"],]).T

z=np.array(data["複勝オッズ"])

#from sklearn.model_selection import train_test_split

#x_train, x_test, t_train, t_test, z_train, z_test = train_test_split(x, t, z, test_size=0.3, random_state=0)

#svc_fit.feature_importances_

# Create a dataframe with features
#feature_dataframe = pd.DataFrame( {'features': cols,
#      'Random Forest feature importances': rf_features,
#      'Extra Trees feature importances': et_features,
#      'AdaBoost feature importances': ada_features,
#      'Gradient Boost feature importances': gb_features,
#      'SVC':svc_features,
#})


#feature_dataframe['mean']=feature_dataframe.mean(axis=1)

# stack base predicts for training meta model
#stacked_predictions = np.column_stack((rf_fit.predict(x_train),et_fit.predict(x_train),ada_fit.predict(x_train),gb_fit.predict(x_train),svc_fit.predict(x_train)))



polymetamnalicac

# train meta model 
from sklearn.linear_model import LinearRegression
#meta_model = LinearRegression()
#meta_model.fit(stacked_predictions, t_train)
from sklearn import preprocessing
satsuki = pd.read_csv('haruten.csv', index_col=0)
mm = preprocessing.MinMaxScaler() # インスタンスの作成
satsuki_seiki = mm.fit_transform(satsuki)
arima = pd.read_csv('arima.csv', index_col=0)
from sklearn.ensemble import VotingClassifier

estimators = [
        ('svc', SVC()),
        ('rf', RandomForestClassifier()),
        ('et', ExtraTreesClassifier()),
        ('ada', AdaBoostClassifier()),
        ('gb', GradientBoostingClassifier()),   
]

sum = 0
buy = 0
voting = VotingClassifier(estimators)
voting.fit(x,t)
print(voting.predict(satsuki_seiki))
