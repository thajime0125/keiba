# -*- coding: utf-8 -*-
"""keiba_test_20191218_01.ipynb のコピー

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vCE0IfmxAyizdhA6TfEfrNAReGWhCZAR
"""

# Commented out IPython magic to ensure Python compatibility.
#import 
import pandas as pd
import numpy as np
import re
import sklearn
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore')

# Going to use these 5 base models for the stacking
from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, 
                              GradientBoostingClassifier, ExtraTreesClassifier)
from sklearn.svm import SVC
from sklearn.model_selection import KFold

from collections import defaultdict

import numpy as np
from sklearn import datasets
#from sklearn.ensemble import VotingRegression
from sklearn.linear_model import LogisticRegression
#from sklearn.neighbors import KNeighborsRegression
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.naive_bayes import GaussianNB



data = pd.read_csv("seikika3.csv", index_col=0)

data=data.astype(float)

data=data.dropna()

data.isnull().sum()

t=np.array(data['着順']).T
#t.shape

x=np.array([data['芝ダ'],data['距離'],data['天候'],data['馬場'],data['馬番'],data['斤量'],data['単勝'],data['人気'],data['馬体重'],data['増減'],]).T
#x.shape
z=np.array(data["単勝オッズ"])

from sklearn.model_selection import train_test_split

x_train,x_test,t_train,t_test,z_train,z_test = train_test_split(x,t,z, test_size=0.3,random_state=0)

from sklearn.model_selection import train_test_split

x_train1,x_train2,t_train1,t_train2 = train_test_split(x_train,t_train,test_size=0.5,random_state=0)

from sklearn.ensemble import VotingRegressor
from sklearn.linear_model import LinearRegression

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import GradientBoostingRegressor

estimators5=[
            ("lr",LinearRegression()),
            ("ls",Lasso()),
            ("en",ElasticNet()),
            ("dtr",DecisionTreeRegressor()),
            ("kr",KNeighborsRegressor()),
            ("gb",GradientBoostingRegressor())
]

voting5 = VotingRegressor(estimators5,weights=[1,1,1,1.5,1,1.5])
#oting5.fit(x_train1,t_train1)
#ここから別のやつ


sum = 0
buy = 0
voting5.fit(x_train,t_train)
t_predict = voting5.predict(x_test)
for i, yosoku in enumerate(x_test):
    if voting5.predict(x_test[i:i+1]) < 0.3:
        if t_test[i]==0:
            sum += z_test[i]
        buy += 1

print(sum)
print(buy)
print(sum/buy)
